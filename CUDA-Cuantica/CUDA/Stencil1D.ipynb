{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stencil1D.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfM730eEYCxR"
      },
      "source": [
        "Primera versión: sin memoria compartida"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhy6a5ZCYFK_",
        "outputId": "975e4da1-0b72-4e83-fb0c-c6151fd72052"
      },
      "source": [
        "%%writefile stenciltest.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define RADIUS        3\n",
        "#define BLOCK_SIZE    256\n",
        "#define NUM_ELEMENTS  (4096*2)\n",
        "\n",
        "// CUDA API error checking macro\n",
        "#define cudaCheck(error) \\\n",
        "  if (error != cudaSuccess) { \\\n",
        "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
        "      cudaGetErrorString(error), \\\n",
        "      __FILE__, __LINE__); \\\n",
        "    exit(1); \\\n",
        "  }\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out) \n",
        "{\n",
        "    int index = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "\n",
        "    // Apply the stencil\n",
        "    int result = 0;\n",
        "    for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
        "        result += in[index + offset];\n",
        "\n",
        "    // Store the result\n",
        "    out[index-RADIUS] = result;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  unsigned int i;\n",
        "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
        "  int *d_in, *d_out;\n",
        "\n",
        "  // Initialize host data\n",
        "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
        "    h_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
        "\n",
        "  // Allocate space on the device\n",
        "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
        "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
        "\n",
        "  // Copy input data to device\n",
        "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
        "\n",
        "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
        "\n",
        "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // Verify every out value is the expected output\n",
        "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
        "    if (h_out[i] != (2*RADIUS + 1))\n",
        "    {\n",
        "      printf(\"Element h_out[%d] == %d != %d\\n\", i, h_out[i],(2*RADIUS + 1));\n",
        "      break;\n",
        "    }\n",
        "\n",
        "  if (i == NUM_ELEMENTS)\n",
        "    printf(\"SUCCESS!\\n\");\n",
        "\n",
        "  // Free out memory\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting stenciltest.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUGIvLdFfO2e",
        "outputId": "d35ffc30-285a-49d3-9e68-fe466e76bba7"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true stenciltest.cu -o ./stenciltest -lcudadevrt\n",
        "!nvprof ./stenciltest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "==396== NVPROF is profiling process 396, command: ./stenciltest\n",
            "==396== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.\n",
            "SUCCESS!\n",
            "==396== Profiling application: ./stenciltest\n",
            "==396== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   44.57%  9.0560us         1  9.0560us  9.0560us  9.0560us  [CUDA memcpy HtoD]\n",
            "                   33.39%  6.7840us         1  6.7840us  6.7840us  6.7840us  [CUDA memcpy DtoH]\n",
            "                   22.05%  4.4800us         1  4.4800us  4.4800us  4.4800us  stencil_1d(int*, int*)\n",
            "      API calls:   99.45%  199.90ms         2  99.952ms  8.5570us  199.90ms  cudaMalloc\n",
            "                    0.28%  555.74us         1  555.74us  555.74us  555.74us  cuDeviceTotalMem\n",
            "                    0.13%  252.08us       101  2.4950us     152ns  116.96us  cuDeviceGetAttribute\n",
            "                    0.07%  142.84us         2  71.418us  14.283us  128.55us  cudaFree\n",
            "                    0.04%  89.404us         2  44.702us  36.690us  52.714us  cudaMemcpy\n",
            "                    0.01%  29.212us         1  29.212us  29.212us  29.212us  cuDeviceGetName\n",
            "                    0.01%  25.984us         1  25.984us  25.984us  25.984us  cudaLaunchKernel\n",
            "                    0.00%  6.8080us         1  6.8080us  6.8080us  6.8080us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.3290us         3     776ns     208ns  1.2700us  cuDeviceGetCount\n",
            "                    0.00%  1.6790us         2     839ns     328ns  1.3510us  cuDeviceGet\n",
            "                    0.00%     298ns         1     298ns     298ns     298ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF4z8K3sUrrO",
        "outputId": "a0814dea-7371-4a1b-9ec7-6fd261ce9213"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov  7 21:34:19 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0    74W / 149W |      0MiB / 11441MiB |      6%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6jNC8f8sYeB"
      },
      "source": [
        "Segunda versión: Memoria compartida pero sin usar syncthreads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw6mOz4Ob_ah",
        "outputId": "5d422386-fe6e-4d94-d88d-72309cdb651a"
      },
      "source": [
        "%%writefile stencilshared.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define RADIUS        3\n",
        "#define BLOCK_SIZE    256\n",
        "#define NUM_ELEMENTS  (4096*2)\n",
        "\n",
        "// CUDA API error checking macro\n",
        "#define cudaCheck(error) \\\n",
        "  if (error != cudaSuccess) { \\\n",
        "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
        "      cudaGetErrorString(error), \\\n",
        "      __FILE__, __LINE__); \\\n",
        "    exit(1); \\\n",
        "  }\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out) \n",
        "{\n",
        "    __shared__ int temp[BLOCK_SIZE + 2 * RADIUS];\n",
        "    int gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "    int lindex = threadIdx.x + RADIUS;\n",
        "\n",
        "    // Read input elements into shared memory\n",
        "    temp[lindex] = in[gindex];\n",
        "    if (threadIdx.x < RADIUS) \n",
        "    {\n",
        "        temp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "        temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
        "    }\n",
        "\n",
        "    // Make sure all threads get to this point before proceeding!\n",
        "    //__syncthreads();\n",
        "\n",
        "    // Apply the stencil\n",
        "    int result = 0;\n",
        "    for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
        "        result += temp[lindex + offset];\n",
        "\n",
        "    // Store the result\n",
        "    out[gindex-RADIUS] = result;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  unsigned int i;\n",
        "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
        "  int *d_in, *d_out;\n",
        "\n",
        "  // Initialize host data\n",
        "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
        "    h_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
        "\n",
        "  // Allocate space on the device\n",
        "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
        "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
        "\n",
        "  // Copy input data to device\n",
        "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
        "\n",
        "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
        "\n",
        "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // Verify every out value is 7\n",
        "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
        "    if (h_out[i] != 7)\n",
        "    {\n",
        "      printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
        "      break;\n",
        "    }\n",
        "\n",
        "  //if (i == NUM_ELEMENTS)\n",
        "  //  printf(\"SUCCESS!\\n\");\n",
        "\n",
        "  // Free out memory\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing stencilshared.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMzLBa7Cc-Sw",
        "outputId": "02afcda0-90cd-4080-affa-eca3b7355d0d"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true stencilshared.cu -o ./stencilshared -lcudadevrt\n",
        "!nvprof ./stencilshared"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "==457== NVPROF is profiling process 457, command: ./stencilshared\n",
            "==457== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.\n",
            "==457== Profiling application: ./stencilshared\n",
            "==457== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   46.92%  9.0240us         1  9.0240us  9.0240us  9.0240us  [CUDA memcpy HtoD]\n",
            "                   35.27%  6.7840us         1  6.7840us  6.7840us  6.7840us  [CUDA memcpy DtoH]\n",
            "                   17.80%  3.4240us         1  3.4240us  3.4240us  3.4240us  stencil_1d(int*, int*)\n",
            "      API calls:   99.44%  198.32ms         2  99.159ms  5.0320us  198.31ms  cudaMalloc\n",
            "                    0.31%  608.84us         1  608.84us  608.84us  608.84us  cuDeviceTotalMem\n",
            "                    0.10%  205.28us       101  2.0320us     152ns  88.182us  cuDeviceGetAttribute\n",
            "                    0.06%  117.16us         2  58.578us  9.2760us  107.88us  cudaFree\n",
            "                    0.05%  89.905us         2  44.952us  39.096us  50.809us  cudaMemcpy\n",
            "                    0.03%  50.590us         1  50.590us  50.590us  50.590us  cuDeviceGetName\n",
            "                    0.01%  25.049us         1  25.049us  25.049us  25.049us  cudaLaunchKernel\n",
            "                    0.01%  20.442us         1  20.442us  20.442us  20.442us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.5130us         3     837ns     188ns  1.1890us  cuDeviceGetCount\n",
            "                    0.00%  1.6700us         2     835ns     497ns  1.1730us  cuDeviceGet\n",
            "                    0.00%     282ns         1     282ns     282ns     282ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6xHoMuYD41j",
        "outputId": "02287bc6-dcec-4f8f-928d-d26de0842990"
      },
      "source": [
        "!nvprof ./stencilshared"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Error: application not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDZqrLr4tvUr"
      },
      "source": [
        "Tercera versión: con Syncthreads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61uIAu-dpIPp",
        "outputId": "fcb3689f-d373-45d7-9c6a-08c9e9e8c89c"
      },
      "source": [
        "%%writefile stencilshared_sync.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define RADIUS        3\n",
        "#define BLOCK_SIZE    256\n",
        "#define NUM_ELEMENTS  (4096*2)\n",
        "\n",
        "// CUDA API error checking macro\n",
        "#define cudaCheck(error) \\\n",
        "  if (error != cudaSuccess) { \\\n",
        "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
        "      cudaGetErrorString(error), \\\n",
        "      __FILE__, __LINE__); \\\n",
        "    exit(1); \\\n",
        "  }\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out) \n",
        "{\n",
        "    __shared__ int temp[BLOCK_SIZE + 2 * RADIUS];\n",
        "    int gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "    int lindex = threadIdx.x + RADIUS;\n",
        " \n",
        "\n",
        "    //Read input elements into shared memory\n",
        "    temp[lindex] = in[gindex];\n",
        "    if (threadIdx.x < RADIUS) \n",
        "    {\n",
        "        temp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "        temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
        "    }\n",
        "\n",
        "    // Make sure all threads get to this point before proceeding!\n",
        "    __syncthreads();\n",
        "\n",
        "    // Apply the stencil\n",
        "    int result = 0;\n",
        "    for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
        "        result += temp[lindex + offset];\n",
        "\n",
        "    // Store the result\n",
        "    out[gindex-RADIUS] = result;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  unsigned int i;\n",
        "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
        "  int *d_in, *d_out;\n",
        "\n",
        "  // Initialize host data\n",
        "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
        "    h_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
        "\n",
        "  // Allocate space on the device\n",
        "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
        "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
        "\n",
        "  // Copy input data to device\n",
        "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
        "\n",
        "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
        "\n",
        "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // Verify every out value is (2*RADIUS + 1)\n",
        "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
        "    if (h_out[i] != (2*RADIUS + 1))\n",
        "    {\n",
        "      printf(\"Element h_out[%d] == %d != %d\\n\", i, h_out[i],(2*RADIUS + 1));\n",
        "      break;\n",
        "    }\n",
        "\n",
        "  //if (i == NUM_ELEMENTS)\n",
        "   // printf(\"SUCCESS!\\n\");\n",
        "\n",
        "  // Free out memory\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing stencilshared_sync.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmZc21_atz43",
        "outputId": "6d43358c-1b9a-4450-c2af-50e9cd5b5c66"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true stencilshared_sync.cu -o ./stencilshared_sync -lcudadevrt\n",
        "!nvprof ./stencilshared_sync"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "==257== NVPROF is profiling process 257, command: ./stencilshared_sync\n",
            "==257== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.\n",
            "==257== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version \n",
            "==257== Profiling application: ./stencilshared_sync\n",
            "==257== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   45.75%  9.1200us         1  9.1200us  9.1200us  9.1200us  [CUDA memcpy HtoD]\n",
            "                   34.19%  6.8160us         1  6.8160us  6.8160us  6.8160us  [CUDA memcpy DtoH]\n",
            "                   20.06%  4.0000us         1  4.0000us  4.0000us  4.0000us  stencil_1d(int*, int*)\n",
            "      API calls:   99.45%  189.43ms         2  94.717ms  4.6120us  189.43ms  cudaMalloc\n",
            "                    0.27%  523.69us         1  523.69us  523.69us  523.69us  cuDeviceTotalMem\n",
            "                    0.10%  196.02us       101  1.9400us     147ns  93.412us  cuDeviceGetAttribute\n",
            "                    0.08%  145.08us         2  72.538us  9.1580us  135.92us  cudaFree\n",
            "                    0.04%  82.073us         2  41.036us  28.393us  53.680us  cudaMemcpy\n",
            "                    0.03%  61.897us         1  61.897us  61.897us  61.897us  cudaLaunchKernel\n",
            "                    0.02%  30.014us         1  30.014us  30.014us  30.014us  cuDeviceGetName\n",
            "                    0.00%  5.1580us         1  5.1580us  5.1580us  5.1580us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.0940us         3     698ns     303ns  1.3250us  cuDeviceGetCount\n",
            "                    0.00%  1.6160us         2     808ns     392ns  1.2240us  cuDeviceGet\n",
            "                    0.00%     285ns         1     285ns     285ns     285ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-qyh27vWsvL",
        "outputId": "813eca8c-dffd-4be5-c089-2093507231c5"
      },
      "source": [
        "%%writefile o_stencil_np.cu\n",
        "#include <iostream>\n",
        "#include <algorithm>\n",
        "using namespace std;\n",
        "\n",
        "#define N (4096*2)\n",
        "#define RADIUS 3\n",
        "#define BLOCK_SIZE 256\n",
        "__global__ void stencil_1d(int *in, int *out) {\n",
        "    // Índice global de la posición central de los datos que va a usar el thread\n",
        "    int index = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "\n",
        "    // Realizamos la operación del stencil\n",
        "    int result = 0;\n",
        "    for (int offset = -RADIUS; offset <= RADIUS; offset++)\n",
        "        result += in[index + offset];\n",
        "\n",
        "    // Guardamos el resultado\n",
        "    out[index-RADIUS] = result;\n",
        "}\n",
        "void fill_ints(int *x, int n)\n",
        "{\n",
        "\tfill_n(x, n, 1);\n",
        "}\n",
        "int main(void)\n",
        "{\n",
        "\tint *in, *out;\t// host copies of a, b, c\n",
        "\tint *d_in, *d_out;\t// device copies of a, b, c\n",
        "\tint size = (N + 2 *RADIUS) *sizeof(int);\n",
        "\t// Alloc space for host copies and setup values\n",
        "\tin = (int*) malloc(size);\n",
        "\tfill_ints(in, N + 2 *RADIUS);\n",
        "\tout = (int*) malloc(size);\n",
        "\tfill_ints(out, N + 2 *RADIUS);\n",
        "\t// Alloc space for device copies\n",
        "\tcudaMalloc((void **) &d_in, size);\n",
        "\tcudaMalloc((void **) &d_out, size);\n",
        "\t// Copy to device\n",
        "\tcudaMemcpy(d_in, in, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_out, out, size, cudaMemcpyHostToDevice);\n",
        "\t// Launch stencil_1d() kernel on GPU\n",
        "\tstencil_1d <<<(N + BLOCK_SIZE - 1 ) / BLOCK_SIZE, BLOCK_SIZE>>> (d_in + RADIUS, d_out + RADIUS);\n",
        "\t// Copy result back to host\n",
        "\tcudaMemcpy(out, d_out, size, cudaMemcpyDeviceToHost);\n",
        "\t// Cleanup\n",
        "\tfree(in);\n",
        "\tfree(out);\n",
        "\tcudaFree(d_in);\n",
        "\tcudaFree(d_out);\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing o_stencil_np.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_RVYDYLW6tA",
        "outputId": "350814fb-e073-4778-a20f-953356645241"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true o_stencil_np.cu -o ./o_stencil_np -lcudadevrt\n",
        "!nvprof ./o_stencil_np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "==567== NVPROF is profiling process 567, command: ./o_stencil_np\n",
            "==567== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.\n",
            "==567== Profiling application: ./o_stencil_np\n",
            "==567== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   61.29%  17.984us         2  8.9920us  8.8640us  9.1200us  [CUDA memcpy HtoD]\n",
            "                   23.23%  6.8160us         1  6.8160us  6.8160us  6.8160us  [CUDA memcpy DtoH]\n",
            "                   15.49%  4.5440us         1  4.5440us  4.5440us  4.5440us  stencil_1d(int*, int*)\n",
            "      API calls:   99.47%  199.51ms         2  99.757ms  16.964us  199.50ms  cudaMalloc\n",
            "                    0.26%  513.14us         1  513.14us  513.14us  513.14us  cuDeviceTotalMem\n",
            "                    0.12%  241.40us       101  2.3900us     173ns  109.48us  cuDeviceGetAttribute\n",
            "                    0.06%  123.83us         2  61.916us  8.9980us  114.83us  cudaFree\n",
            "                    0.04%  88.883us         3  29.627us  26.695us  32.793us  cudaMemcpy\n",
            "                    0.02%  43.016us         1  43.016us  43.016us  43.016us  cuDeviceGetName\n",
            "                    0.02%  38.368us         1  38.368us  38.368us  38.368us  cudaLaunchKernel\n",
            "                    0.00%  5.4200us         1  5.4200us  5.4200us  5.4200us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.9310us         3     643ns     291ns     901ns  cuDeviceGetCount\n",
            "                    0.00%  1.5940us         2     797ns     294ns  1.3000us  cuDeviceGet\n",
            "                    0.00%     317ns         1     317ns     317ns     317ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2GBPkbRVFdK",
        "outputId": "beb5f28f-2632-480a-c5ce-304aac15d9e8"
      },
      "source": [
        "%%writefile o_stencil.cu\n",
        "#include <iostream>\n",
        "#include <algorithm>\n",
        "using namespace std;\n",
        "\n",
        "#define N (4096*2)\n",
        "#define RADIUS 3\n",
        "#define BLOCK_SIZE 256\n",
        "__global__ void stencil_1d(int *in, int *out)\n",
        "{\n",
        "\t__shared__ int temp[BLOCK_SIZE + 2 *RADIUS];\n",
        "\tint gindex = threadIdx.x + blockIdx.x *blockDim.x;\n",
        "\tint lindex = threadIdx.x + RADIUS;\n",
        "\t// Read input elements into shared memory\n",
        "\ttemp[lindex] = in[gindex];\n",
        "\tif (threadIdx.x < RADIUS)\n",
        "\t{\n",
        "\t\ttemp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "\t\ttemp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
        "\t}\n",
        "\t// Synchronize (ensure all the data is available)\n",
        "\t//__syncthreads();\n",
        "\t// Apply the stencil\n",
        "\tint result = 0;\n",
        "\tfor (int offset = -RADIUS; offset<= RADIUS; offset++)\n",
        "\t\tresult += temp[lindex + offset];\n",
        "\t// Store the result\n",
        "\tout[gindex] = result;\n",
        "}\n",
        "void fill_ints(int *x, int n)\n",
        "{\n",
        "\tfill_n(x, n, 1);\n",
        "}\n",
        "int main(void)\n",
        "{\n",
        "\tint *in, *out;\t// host copies of a, b, c\n",
        "\tint *d_in, *d_out;\t// device copies of a, b, c\n",
        "\tint size = (N + 2 *RADIUS) *sizeof(int);\n",
        "\t// Alloc space for host copies and setup values\n",
        "\tin = (int*) malloc(size);\n",
        "\tfill_ints(in, N + 2 *RADIUS);\n",
        "\tout = (int*) malloc(size);\n",
        "\tfill_ints(out, N + 2 *RADIUS);\n",
        "\t// Alloc space for device copies\n",
        "\tcudaMalloc((void **) &d_in, size);\n",
        "\tcudaMalloc((void **) &d_out, size);\n",
        "\t// Copy to device\n",
        "\tcudaMemcpy(d_in, in, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_out, out, size, cudaMemcpyHostToDevice);\n",
        "\t// Launch stencil_1d() kernel on GPU\n",
        "\tstencil_1d <<<(N + BLOCK_SIZE - 1 ) / BLOCK_SIZE, BLOCK_SIZE>>> (d_in + RADIUS, d_out + RADIUS);\n",
        "\t// Copy result back to host\n",
        "\tcudaMemcpy(out, d_out, size, cudaMemcpyDeviceToHost);\n",
        "\t// Cleanup\n",
        "\tfree(in);\n",
        "\tfree(out);\n",
        "\tcudaFree(d_in);\n",
        "\tcudaFree(d_out);\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting o_stencil.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2FWsIedVMSx",
        "outputId": "af257761-17e0-4d9a-abde-a4ddd23ad36a"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true o_stencil.cu -o ./o_stencil -lcudadevrt\n",
        "!nvprof ./o_stencil"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "==505== NVPROF is profiling process 505, command: ./o_stencil\n",
            "==505== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.\n",
            "==505== Profiling application: ./o_stencil\n",
            "==505== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   63.68%  17.952us         2  8.9760us  8.8640us  9.0880us  [CUDA memcpy HtoD]\n",
            "                   24.29%  6.8480us         1  6.8480us  6.8480us  6.8480us  [CUDA memcpy DtoH]\n",
            "                   12.03%  3.3920us         1  3.3920us  3.3920us  3.3920us  stencil_1d(int*, int*)\n",
            "      API calls:   99.46%  197.26ms         2  98.628ms  4.7020us  197.25ms  cudaMalloc\n",
            "                    0.28%  559.56us         1  559.56us  559.56us  559.56us  cuDeviceTotalMem\n",
            "                    0.10%  197.31us       101  1.9530us     165ns  82.106us  cuDeviceGetAttribute\n",
            "                    0.08%  159.95us         2  79.975us  8.3610us  151.59us  cudaFree\n",
            "                    0.05%  89.868us         3  29.956us  26.482us  34.831us  cudaMemcpy\n",
            "                    0.01%  28.654us         1  28.654us  28.654us  28.654us  cuDeviceGetName\n",
            "                    0.01%  24.893us         1  24.893us  24.893us  24.893us  cudaLaunchKernel\n",
            "                    0.00%  7.7680us         1  7.7680us  7.7680us  7.7680us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.1350us         3     711ns     221ns  1.0340us  cuDeviceGetCount\n",
            "                    0.00%  1.6970us         2     848ns     302ns  1.3950us  cuDeviceGet\n",
            "                    0.00%     306ns         1     306ns     306ns     306ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOtPgR3jVRE5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}